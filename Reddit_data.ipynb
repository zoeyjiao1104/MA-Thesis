{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5d9739c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psaw\n",
      "  Downloading psaw-0.1.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from psaw) (2.27.1)\n",
      "Requirement already satisfied: Click in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from psaw) (8.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from requests->psaw) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from requests->psaw) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from requests->psaw) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages (from requests->psaw) (1.26.8)\n",
      "Installing collected packages: psaw\n",
      "Successfully installed psaw-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install psaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef754f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724b2d1",
   "metadata": {},
   "source": [
    "### Scrape Reddit data (posts and comments) on a certain subreddit keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5037edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from psaw import PushshiftAPI\n",
    "import json, pickle\n",
    "from multiprocessing import Process, Manager\n",
    "import timeit, random, bz2, lzma\n",
    "from psaw import PushshiftAPI\n",
    "import gzip, os\n",
    "\n",
    "\n",
    "api = PushshiftAPI()\n",
    "\n",
    "def crawl_subreddit(sub, directory, start_date, end_date, comments = False):\n",
    "    #Example:  start_epoch: '20200101', end_epoch '20200303'\n",
    "    start_epoch = datetime.strptime(start_date, '%Y%m%d')\n",
    "    end_epoch = datetime.strptime(end_date, '%Y%m%d')\n",
    "    \n",
    "    prefix = \"posts\"\n",
    "    if comments:\n",
    "        prefix = 'comments'\n",
    "        \n",
    "    directory = \"{}{}/{}/\".format(directory, prefix, sub)\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    if comments:\n",
    "        gen = api.search_comments(subreddit = sub, after = start_epoch, before = end_epoch)\n",
    "    else:\n",
    "        gen = api.search_submissions(subreddit = sub, after = start_epoch, before = end_epoch)\n",
    "        \n",
    "    \n",
    "    for dic in gen:\n",
    "        dic = dic.d_\n",
    "        created_time = datetime.fromtimestamp(float(dic['created_utc']))\n",
    "        year = created_time.year\n",
    "        month = created_time.month\n",
    "        month_str = str(month)\n",
    "        if len(month_str) < 2:\n",
    "            month_str = \"0{}\".format(month_str)\n",
    "        with gzip.open(\"{}{}_jsonlists.gz\".format(directory, prefix), \"at\") as fout:\n",
    "            fout.write(\"%s\\n\" % json.dumps(dic))\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    crawl_subreddit('lactoseintolerant', 'data/', '20171025', '20221025', comments = False)\n",
    "    crawl_subreddit('lactoseintolerant', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee380333",
   "metadata": {},
   "source": [
    "#### 1. first subreddit -'lactoseintolerance' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90ce1e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n"
     ]
    }
   ],
   "source": [
    "crawl_subreddit('lactoseintolerance', 'data/', '20171025', '20221025', comments = False)\n",
    "crawl_subreddit('lactoseintolerance', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5aa42f",
   "metadata": {},
   "source": [
    "##### Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a8e1fe",
   "metadata": {},
   "source": [
    "Open as a dataframe from a saved json file for all posts under this subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6687d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/lactoseintolerance/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df3 = pd.read_json(inputfile, lines = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe595ed",
   "metadata": {},
   "source": [
    "Select columns that I'm interested in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b061cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df2 = df3[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68981a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f6760",
   "metadata": {},
   "source": [
    "##### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8c3d06",
   "metadata": {},
   "source": [
    "Open as a dataframe from a saved json file for all comments under this subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a54e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/comments/lactoseintolerance/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df4 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b7edf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df2 = df4[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc1243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64806696",
   "metadata": {},
   "source": [
    "#### 1. Second subreddit -'lactoseintolerant' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff38eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/lactoseintolerant/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df = pd.read_json(inputfile, lines = True)\n",
    "\n",
    "#df.to_csv('csvfile.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8360017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>...</th>\n",
       "      <th>edited</th>\n",
       "      <th>steward_reports</th>\n",
       "      <th>removed_by</th>\n",
       "      <th>updated_utc</th>\n",
       "      <th>og_description</th>\n",
       "      <th>og_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>rte_mode</th>\n",
       "      <th>author_id</th>\n",
       "      <th>brand_safe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MyOversoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_xqick</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>brainsareforlosers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_caai4dga</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>menickc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_10ymfk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kenney93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_bxyt048l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MyToesAreBeans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_60ilpllr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments              author  \\\n",
       "0            []                  0.0          MyOversoul   \n",
       "1            []                  0.0  brainsareforlosers   \n",
       "2            []                  0.0             menickc   \n",
       "3            []                  0.0            Kenney93   \n",
       "4            []                  0.0      MyToesAreBeans   \n",
       "\n",
       "   author_flair_css_class author_flair_richtext author_flair_text  \\\n",
       "0                     NaN                    []              None   \n",
       "1                     NaN                    []              None   \n",
       "2                     NaN                    []              None   \n",
       "3                     NaN                    []              None   \n",
       "4                     NaN                    []              None   \n",
       "\n",
       "  author_flair_type author_fullname  author_is_blocked  author_patreon_flair  \\\n",
       "0              text        t2_xqick                0.0                   0.0   \n",
       "1              text     t2_caai4dga                0.0                   0.0   \n",
       "2              text       t2_10ymfk                0.0                   0.0   \n",
       "3              text     t2_bxyt048l                0.0                   0.0   \n",
       "4              text     t2_60ilpllr                0.0                   0.0   \n",
       "\n",
       "   ...  edited steward_reports  removed_by  updated_utc  og_description  \\\n",
       "0  ...     NaN             NaN         NaN          NaN             NaN   \n",
       "1  ...     NaN             NaN         NaN          NaN             NaN   \n",
       "2  ...     NaN             NaN         NaN          NaN             NaN   \n",
       "3  ...     NaN             NaN         NaN          NaN             NaN   \n",
       "4  ...     NaN             NaN         NaN          NaN             NaN   \n",
       "\n",
       "  og_title gilded rte_mode author_id  brand_safe  \n",
       "0      NaN    NaN      NaN       NaN         NaN  \n",
       "1      NaN    NaN      NaN       NaN         NaN  \n",
       "2      NaN    NaN      NaN       NaN         NaN  \n",
       "3      NaN    NaN      NaN       NaN         NaN  \n",
       "4      NaN    NaN      NaN       NaN         NaN  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d669ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = df[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74afb4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MyOversoul</td>\n",
       "      <td>1666641624</td>\n",
       "      <td>ycl0xu</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/lactoseintolerant/comments/ycl0xu/making_la...</td>\n",
       "      <td>1</td>\n",
       "      <td>making lactose free dairy products at home</td>\n",
       "      <td>So I made a big batch of ricotta cheese from g...</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brainsareforlosers</td>\n",
       "      <td>1666639469</td>\n",
       "      <td>yck563</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/lactoseintolerant/comments/yck563/possible_...</td>\n",
       "      <td>1</td>\n",
       "      <td>possible lactose intolerance??</td>\n",
       "      <td>hi! hope this is the right place to post this!...</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>menickc</td>\n",
       "      <td>1666582795</td>\n",
       "      <td>yc15g9</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/lactoseintolerant/comments/yc15g9/chocolate...</td>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Milk Kills Me</td>\n",
       "      <td>I eat tons of cheese and dairy products but it...</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenney93</td>\n",
       "      <td>1666566345</td>\n",
       "      <td>ybvo4g</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/lactoseintolerant/comments/ybvo4g/do_we_nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>Do we need to take calcium with vitamin D supp...</td>\n",
       "      <td>I am allergic to nuts, eggs, strawberries, man...</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MyToesAreBeans</td>\n",
       "      <td>1666563325</td>\n",
       "      <td>ybukfx</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/lactoseintolerant/comments/ybukfx/milk/</td>\n",
       "      <td>1</td>\n",
       "      <td>Milk</td>\n",
       "      <td>Is white</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  created_utc      id  num_comments  \\\n",
       "0          MyOversoul   1666641624  ycl0xu             0   \n",
       "1  brainsareforlosers   1666639469  yck563             0   \n",
       "2             menickc   1666582795  yc15g9             0   \n",
       "3            Kenney93   1666566345  ybvo4g             0   \n",
       "4      MyToesAreBeans   1666563325  ybukfx             0   \n",
       "\n",
       "                                           permalink  score  \\\n",
       "0  /r/lactoseintolerant/comments/ycl0xu/making_la...      1   \n",
       "1  /r/lactoseintolerant/comments/yck563/possible_...      1   \n",
       "2  /r/lactoseintolerant/comments/yc15g9/chocolate...      1   \n",
       "3  /r/lactoseintolerant/comments/ybvo4g/do_we_nee...      1   \n",
       "4         /r/lactoseintolerant/comments/ybukfx/milk/      1   \n",
       "\n",
       "                                               title  \\\n",
       "0         making lactose free dairy products at home   \n",
       "1                     possible lactose intolerance??   \n",
       "2                            Chocolate Milk Kills Me   \n",
       "3  Do we need to take calcium with vitamin D supp...   \n",
       "4                                               Milk   \n",
       "\n",
       "                                            selftext          subreddit  \n",
       "0  So I made a big batch of ricotta cheese from g...  lactoseintolerant  \n",
       "1  hi! hope this is the right place to post this!...  lactoseintolerant  \n",
       "2  I eat tons of cheese and dairy products but it...  lactoseintolerant  \n",
       "3  I am allergic to nuts, eggs, strawberries, man...  lactoseintolerant  \n",
       "4                                           Is white  lactoseintolerant  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b930da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/comments/lactoseintolerant/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df2 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a693f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = df2[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1edb7a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Viking603</td>\n",
       "      <td>1666652618</td>\n",
       "      <td>Dude. Been there. Ordered a \"hamburger ' in a ...</td>\n",
       "      <td>itnht1x</td>\n",
       "      <td>t3_ybs9yq</td>\n",
       "      <td>/r/lactoseintolerant/comments/ybs9yq/im_going_...</td>\n",
       "      <td>1</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MyOversoul</td>\n",
       "      <td>1666647377</td>\n",
       "      <td>Interesting thank you for the recipe share!</td>\n",
       "      <td>itn5v15</td>\n",
       "      <td>t1_itn15ih</td>\n",
       "      <td>/r/lactoseintolerant/comments/ycl0xu/making_la...</td>\n",
       "      <td>1</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>matanuki</td>\n",
       "      <td>1666645497</td>\n",
       "      <td>That's wild, I didn't think you could make ric...</td>\n",
       "      <td>itn15ih</td>\n",
       "      <td>t3_ycl0xu</td>\n",
       "      <td>/r/lactoseintolerant/comments/ycl0xu/making_la...</td>\n",
       "      <td>1</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[deleted]</td>\n",
       "      <td>1666644250</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>itmxyeg</td>\n",
       "      <td>t3_ycl0xu</td>\n",
       "      <td>/r/lactoseintolerant/comments/ycl0xu/making_la...</td>\n",
       "      <td>1</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shimerald</td>\n",
       "      <td>1666643897</td>\n",
       "      <td>Stomach and gut issues are pretty common with ...</td>\n",
       "      <td>itmx17n</td>\n",
       "      <td>t3_yck563</td>\n",
       "      <td>/r/lactoseintolerant/comments/yck563/possible_...</td>\n",
       "      <td>1</td>\n",
       "      <td>lactoseintolerant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  created_utc                                               body  \\\n",
       "0   Viking603   1666652618  Dude. Been there. Ordered a \"hamburger ' in a ...   \n",
       "1  MyOversoul   1666647377        Interesting thank you for the recipe share!   \n",
       "2    matanuki   1666645497  That's wild, I didn't think you could make ric...   \n",
       "3   [deleted]   1666644250                                          [removed]   \n",
       "4   Shimerald   1666643897  Stomach and gut issues are pretty common with ...   \n",
       "\n",
       "        id   parent_id                                          permalink  \\\n",
       "0  itnht1x   t3_ybs9yq  /r/lactoseintolerant/comments/ybs9yq/im_going_...   \n",
       "1  itn5v15  t1_itn15ih  /r/lactoseintolerant/comments/ycl0xu/making_la...   \n",
       "2  itn15ih   t3_ycl0xu  /r/lactoseintolerant/comments/ycl0xu/making_la...   \n",
       "3  itmxyeg   t3_ycl0xu  /r/lactoseintolerant/comments/ycl0xu/making_la...   \n",
       "4  itmx17n   t3_yck563  /r/lactoseintolerant/comments/yck563/possible_...   \n",
       "\n",
       "   score          subreddit  \n",
       "0      1  lactoseintolerant  \n",
       "1      1  lactoseintolerant  \n",
       "2      1  lactoseintolerant  \n",
       "3      1  lactoseintolerant  \n",
       "4      1  lactoseintolerant  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3757c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52601, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad103767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8743, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f19a20f",
   "metadata": {},
   "source": [
    "#### 1. Third subreddit -'milkmemes' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0e85bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_subreddit('milkmemes', 'data/', '20171025', '20221025', comments = False)\n",
    "crawl_subreddit('milkmemes', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d70af26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/milkmemes/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df5 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b7e0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/comments/milkmemes/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df6 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b430db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df3 = df5[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]\n",
    "comments_df3 = df6[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb96f9",
   "metadata": {},
   "source": [
    "#### Combine data scraped from these subreddits into one dataframe for posts and comments (separately) - lactose dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30a0a8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9362, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_posts = pd.concat([posts_df,posts_df2, posts_df3])\n",
    "lactose_df_posts.shape #9362 posts in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b948e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54590, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_comments = pd.concat([comments_df, comments_df2, comments_df3])\n",
    "lactose_df_comments.shape #54590 comments in total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc99af",
   "metadata": {},
   "source": [
    "#### Subreddit -'AncestryDNA' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "04da6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_subreddit('AncestryDNA', 'data/', '20171025', '20221025', comments = False)\n",
    "crawl_subreddit('AncestryDNA', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a012cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/AncestryDNA/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df7 = pd.read_json(inputfile, lines = True)\n",
    "with open('data/comments/AncestryDNA/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df8 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "151f02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df4 = df7[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]\n",
    "comments_df4 = df8[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e83828",
   "metadata": {},
   "source": [
    "#### Subreddit -'23andMe' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4984dc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n",
      "/Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 429\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/Users/jieyujiao/opt/anaconda3/lib/python3.8/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n"
     ]
    }
   ],
   "source": [
    "crawl_subreddit('23andMe', 'data/', '20171025', '20221025', comments = False)\n",
    "crawl_subreddit('23andMe', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8888e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/23andMe/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df9 = pd.read_json(inputfile, lines = True)\n",
    "with open('data/comments/23andMe/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df10 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ef163c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df5 = df9[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]\n",
    "comments_df5 = df10[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025ea2f",
   "metadata": {},
   "source": [
    "#### Subreddit -'MyHeritage' from 10/25/2017 to 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b988f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawl_subreddit('MyHeritage', 'data/', '20171025', '20221025', comments = False)\n",
    "crawl_subreddit('MyHeritage', 'data/', '20171025', '20221025', comments = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a028a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/posts/MyHeritage/posts_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df11 = pd.read_json(inputfile, lines = True)\n",
    "with open('data/comments/MyHeritage/comments_jsonlists', encoding='utf-8') as inputfile:\n",
    "    df12 = pd.read_json(inputfile, lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "052bd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df6 = df11[['author','created_utc','id','num_comments','permalink','score','title','selftext','subreddit']]\n",
    "comments_df6 = df12[['author','created_utc','body','id','parent_id','permalink','score','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a0a78",
   "metadata": {},
   "source": [
    "#### combine these three subreddits to a big dataframe (genome dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "417244ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_posts_df = pd.concat([posts_df4, posts_df5, posts_df6])\n",
    "genome_comments_df = pd.concat([comments_df4, comments_df5, comments_df6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f17d5d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89101, 9)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_posts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "afccb1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1168827, 8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_comments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50074ae9",
   "metadata": {},
   "source": [
    "#### save two dataframes into csv (for both posts and comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "da6e18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_posts.to_csv('lactose_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fb0e918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments.to_csv('lactoseintolerant_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "609b5388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# milk_posts_df.to_csv('milk_posts.csv')\n",
    "# milk_comments_df.to_csv('milk_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "accdb129",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_posts_df.to_csv('genome_posts.csv')\n",
    "genome_comments_df.to_csv('genome_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40dea7ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9362, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_posts = pd.read_csv('lactose_posts.csv')\n",
    "lactose_df_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80edd5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54590, 9)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_comments = pd.read_csv('lactoseintolerant_comments.csv')\n",
    "lactose_df_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "578cd63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89101, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_posts_df = pd.read_csv('genome_posts.csv')\n",
    "genome_posts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0ef5e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7j/9bzhlncj1cz1thykbfjsvh3h0000gn/T/ipykernel_57907/836599454.py:1: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  genome_comments_df = pd.read_csv('genome_comments.csv')\n"
     ]
    }
   ],
   "source": [
    "genome_comments_df = pd.read_csv('genome_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b66eafdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206625, 9)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_comments_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb1ef6",
   "metadata": {},
   "source": [
    "### basic cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "58b44fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_posts = lactose_df_posts[lactose_df_posts['author'] != '[deleted]']\n",
    "lactose_df_comments = lactose_df_comments[lactose_df_comments['author'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a371bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_posts_df = genome_posts_df[genome_posts_df['author'] != '[deleted]']\n",
    "genome_comments_df = genome_comments_df[genome_comments_df['author'] != '[deleted]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2746983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9299, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "92de04f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87118, 9)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_posts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1574f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_clean(text): \n",
    "    text = str(text)\n",
    "    text = text.replace('\\\\n',' ')\n",
    "    text = text.replace('&amp',' ')\n",
    "    text = text.replace(';#x200B;',' ')\n",
    "    text = text.replace('nbsp',' ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a5aa73e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments['body'] = lactose_df_comments['body'].apply(lambda x : first_clean(x))\n",
    "lactose_df_posts['selftext'] = lactose_df_posts['selftext'].apply(lambda x : first_clean(x))\n",
    "lactose_df_posts['title'] = lactose_df_posts['title'].apply(lambda x : first_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0e10deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_comments_df['body'] = genome_comments_df['body'].apply(lambda x : first_clean(x))\n",
    "genome_posts_df['selftext'] = genome_posts_df['selftext'].apply(lambda x : first_clean(x))\n",
    "genome_posts_df['title'] = genome_posts_df['title'].apply(lambda x : first_clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "869a2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_posts['created_utc'] = pd.to_datetime(lactose_df_posts['created_utc'], unit='s')\n",
    "lactose_df_comments['created_utc'] = pd.to_datetime(lactose_df_comments['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fb3fdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_posts_df['created_utc'] = pd.to_datetime(genome_posts_df['created_utc'], unit='s')\n",
    "genome_comments_df['created_utc'] = pd.to_datetime(genome_comments_df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c87d540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Manipulation and Storage\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Text Cleaning\n",
    "import string\n",
    "import re\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Generating n-grams\n",
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "045115fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jieyujiao/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6536f637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jieyujiao/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "880066df",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "11abf9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text): \n",
    "    #make string lowercase \n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    #remove links\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    #tokenize\n",
    "    tokens = nltk.word_tokenize(text) \n",
    "    clean_text = []\n",
    "    \n",
    "    #remove stopwords, puncuation, then lemmatize\n",
    "    for word in tokens:\n",
    "        if (word not in stopwords_english and word not in string.punctuation): \n",
    "            token = wordnet_lemmatizer.lemmatize(word)\n",
    "            clean_text.append(token)\n",
    "            \n",
    "    #remove words of length 3 or smaller        \n",
    "    clean_text = [token for token in clean_text if len(token) > 3] \n",
    "            \n",
    "    return clean_text      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e1c3b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments['body_clean'] = lactose_df_comments['body'].apply(lambda x : clean_text(x))\n",
    "lactose_df_posts['selftext_clean'] = lactose_df_posts['selftext'].apply(lambda x : clean_text(x))\n",
    "lactose_df_posts['title_clean'] = lactose_df_posts['title'].apply(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6771b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_comments_df['body_clean'] = genome_comments_df['body'].apply(lambda x : clean_text(x))\n",
    "genome_posts_df['selftext_clean'] = genome_posts_df['selftext'].apply(lambda x : clean_text(x))\n",
    "genome_posts_df['title_clean'] = genome_posts_df['title'].apply(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5bf8434c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext_clean</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isaiah_45__</td>\n",
       "      <td>2022-10-24 23:14:01</td>\n",
       "      <td>ycplol</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycplol/using_wales_as_...</td>\n",
       "      <td>1</td>\n",
       "      <td>Using Wales as an example, do the areas and ci...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[using, wale, example, area, city, highlighted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kb7773</td>\n",
       "      <td>2022-10-24 23:01:39</td>\n",
       "      <td>ycpc0y</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycpc0y/has_anyone_ever...</td>\n",
       "      <td>1</td>\n",
       "      <td>Has anyone ever had an unusual and surprising ...</td>\n",
       "      <td>send me a dm with your story pls! its for a ne...</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[send, story, newspaper, article]</td>\n",
       "      <td>[anyone, ever, unusual, surprising, ancestry/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>takisandrockstar</td>\n",
       "      <td>2022-10-24 22:51:24</td>\n",
       "      <td>ycp40n</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycp40n/dna_results_new...</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA results + new community</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[result, community]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>achkerli</td>\n",
       "      <td>2022-10-24 22:16:27</td>\n",
       "      <td>ycoc5o</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycoc5o/dad_is_100_perc...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dad is 100 percent British and Irish on 23andM...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[percent, british, irish, 23andme, however, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ForgettablePhoenix</td>\n",
       "      <td>2022-10-24 21:59:10</td>\n",
       "      <td>ycnxj6</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycnxj6/my_results_i_kn...</td>\n",
       "      <td>1</td>\n",
       "      <td>My results. I know Parent 1 is my mom and Pare...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[result, know, parent, parent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>blabbedybloobla</td>\n",
       "      <td>2022-10-24 21:18:45</td>\n",
       "      <td>ycmz69</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycmz69/why_are_the_col...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why are the colors switched?</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[color, switched]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bangtan-bot</td>\n",
       "      <td>2022-10-24 20:05:30</td>\n",
       "      <td>ycl5oj</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycl5oj/new_communities...</td>\n",
       "      <td>1</td>\n",
       "      <td>New communities update!</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[community, update]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WanderingWombats</td>\n",
       "      <td>2022-10-24 19:45:11</td>\n",
       "      <td>ycknf2</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycknf2/i_struggle_to_r...</td>\n",
       "      <td>1</td>\n",
       "      <td>I struggle to read cursive so I tested OCR han...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>[struggle, read, cursive, tested, handwriting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fragrant_Ad_7882</td>\n",
       "      <td>2022-10-24 19:01:15</td>\n",
       "      <td>ycjjyq</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycjjyq/old_results_com...</td>\n",
       "      <td>1</td>\n",
       "      <td>Old Results compared with the new ones + commu...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[result, compared, community, family, oh/nw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CNickyD</td>\n",
       "      <td>2022-10-24 18:23:10</td>\n",
       "      <td>ycil6i</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycil6i/this_is_the_pla...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the plantation my 6th great-grandmothe...</td>\n",
       "      <td>I feel surprisingly emotional about thisâ€¦ Weir...</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[feel, surprisingly, emotional, thisâ€¦, weird, ...</td>\n",
       "      <td>[plantation, great-grandmother, mulatto, slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L8PH03NiX</td>\n",
       "      <td>2022-10-24 18:19:04</td>\n",
       "      <td>ycihdg</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycihdg/half_sibling_un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Half sibling uncle, shared DNA percentage?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>[half, sibling, uncle, shared, percentage]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Safe_While3650</td>\n",
       "      <td>2022-10-24 16:05:09</td>\n",
       "      <td>ycf4ce</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycf4ce/updated_results/</td>\n",
       "      <td>1</td>\n",
       "      <td>Updated results.</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[updated, result]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ok_Breadfruit403</td>\n",
       "      <td>2022-10-24 14:47:38</td>\n",
       "      <td>ycd6hm</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ycd6hm/illustrative_dn...</td>\n",
       "      <td>1</td>\n",
       "      <td>Illustrative DNA results (Spanish,German,Apach...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[illustrative, result, spanish, german, apache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fiuman1987</td>\n",
       "      <td>2022-10-24 08:00:16</td>\n",
       "      <td>yc5dx6</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc5dx6/can_someone_she...</td>\n",
       "      <td>1</td>\n",
       "      <td>can someone shed some light onto my GF's resul...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[someone, shed, light, onto, result, suspected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>badgernextdoor</td>\n",
       "      <td>2022-10-24 07:07:16</td>\n",
       "      <td>yc4ldz</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc4ldz/my_moms_mom_got...</td>\n",
       "      <td>1</td>\n",
       "      <td>my mom's mom got her DNA done and am just curi...</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>[done, curious, part]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ttyyffrrii0131</td>\n",
       "      <td>2022-10-24 04:21:20</td>\n",
       "      <td>yc1wos</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc1wos/heres_some_of_t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Hereâ€™s some of the tests Iâ€™ve taken. IMO MyHer...</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[test, taken, myheritage, worst, estimate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>katieladysketti</td>\n",
       "      <td>2022-10-24 03:10:52</td>\n",
       "      <td>yc0lsq</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc0lsq/mine_sons_ances...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mine  ; Son's Ancestry Results</td>\n",
       "      <td></td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mine, ancestry, result]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AndrewtheRey</td>\n",
       "      <td>2022-10-24 03:10:30</td>\n",
       "      <td>yc0ljk</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc0ljk/is_it_rare_for_...</td>\n",
       "      <td>1</td>\n",
       "      <td>Is it rare for a fully colonial WASP American ...</td>\n",
       "      <td>[removed]\\n\\n[View Poll](https://www.reddit.co...</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed, view, poll, http, //www.reddit.com/p...</td>\n",
       "      <td>[rare, fully, colonial, wasp, american, scotland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BeinlausiMentegh</td>\n",
       "      <td>2022-10-24 02:43:19</td>\n",
       "      <td>yc033o</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/yc033o/is_my_irish_sco...</td>\n",
       "      <td>1</td>\n",
       "      <td>is my Irish, Scottish?</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>[irish, scottish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chipperbro</td>\n",
       "      <td>2022-10-24 02:21:43</td>\n",
       "      <td>ybzo6m</td>\n",
       "      <td>0</td>\n",
       "      <td>/r/AncestryDNA/comments/ybzo6m/adopted_child_i...</td>\n",
       "      <td>1</td>\n",
       "      <td>adopted child interested in ethnicity</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>AncestryDNA</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>[adopted, child, interested, ethnicity]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author         created_utc      id  num_comments  \\\n",
       "0          isaiah_45__ 2022-10-24 23:14:01  ycplol             0   \n",
       "1               kb7773 2022-10-24 23:01:39  ycpc0y             0   \n",
       "2     takisandrockstar 2022-10-24 22:51:24  ycp40n             0   \n",
       "3             achkerli 2022-10-24 22:16:27  ycoc5o             0   \n",
       "4   ForgettablePhoenix 2022-10-24 21:59:10  ycnxj6             0   \n",
       "5      blabbedybloobla 2022-10-24 21:18:45  ycmz69             0   \n",
       "6          bangtan-bot 2022-10-24 20:05:30  ycl5oj             0   \n",
       "7     WanderingWombats 2022-10-24 19:45:11  ycknf2             0   \n",
       "8     Fragrant_Ad_7882 2022-10-24 19:01:15  ycjjyq             0   \n",
       "9              CNickyD 2022-10-24 18:23:10  ycil6i             0   \n",
       "10           L8PH03NiX 2022-10-24 18:19:04  ycihdg             0   \n",
       "11      Safe_While3650 2022-10-24 16:05:09  ycf4ce             0   \n",
       "12    Ok_Breadfruit403 2022-10-24 14:47:38  ycd6hm             0   \n",
       "13          Fiuman1987 2022-10-24 08:00:16  yc5dx6             0   \n",
       "14      badgernextdoor 2022-10-24 07:07:16  yc4ldz             0   \n",
       "15      Ttyyffrrii0131 2022-10-24 04:21:20  yc1wos             0   \n",
       "16     katieladysketti 2022-10-24 03:10:52  yc0lsq             0   \n",
       "17        AndrewtheRey 2022-10-24 03:10:30  yc0ljk             0   \n",
       "18    BeinlausiMentegh 2022-10-24 02:43:19  yc033o             0   \n",
       "19          chipperbro 2022-10-24 02:21:43  ybzo6m             0   \n",
       "\n",
       "                                            permalink  score  \\\n",
       "0   /r/AncestryDNA/comments/ycplol/using_wales_as_...      1   \n",
       "1   /r/AncestryDNA/comments/ycpc0y/has_anyone_ever...      1   \n",
       "2   /r/AncestryDNA/comments/ycp40n/dna_results_new...      1   \n",
       "3   /r/AncestryDNA/comments/ycoc5o/dad_is_100_perc...      1   \n",
       "4   /r/AncestryDNA/comments/ycnxj6/my_results_i_kn...      1   \n",
       "5   /r/AncestryDNA/comments/ycmz69/why_are_the_col...      1   \n",
       "6   /r/AncestryDNA/comments/ycl5oj/new_communities...      1   \n",
       "7   /r/AncestryDNA/comments/ycknf2/i_struggle_to_r...      1   \n",
       "8   /r/AncestryDNA/comments/ycjjyq/old_results_com...      1   \n",
       "9   /r/AncestryDNA/comments/ycil6i/this_is_the_pla...      1   \n",
       "10  /r/AncestryDNA/comments/ycihdg/half_sibling_un...      1   \n",
       "11    /r/AncestryDNA/comments/ycf4ce/updated_results/      1   \n",
       "12  /r/AncestryDNA/comments/ycd6hm/illustrative_dn...      1   \n",
       "13  /r/AncestryDNA/comments/yc5dx6/can_someone_she...      1   \n",
       "14  /r/AncestryDNA/comments/yc4ldz/my_moms_mom_got...      1   \n",
       "15  /r/AncestryDNA/comments/yc1wos/heres_some_of_t...      1   \n",
       "16  /r/AncestryDNA/comments/yc0lsq/mine_sons_ances...      1   \n",
       "17  /r/AncestryDNA/comments/yc0ljk/is_it_rare_for_...      1   \n",
       "18  /r/AncestryDNA/comments/yc033o/is_my_irish_sco...      1   \n",
       "19  /r/AncestryDNA/comments/ybzo6m/adopted_child_i...      1   \n",
       "\n",
       "                                                title  \\\n",
       "0   Using Wales as an example, do the areas and ci...   \n",
       "1   Has anyone ever had an unusual and surprising ...   \n",
       "2                         DNA results + new community   \n",
       "3   Dad is 100 percent British and Irish on 23andM...   \n",
       "4   My results. I know Parent 1 is my mom and Pare...   \n",
       "5                        Why are the colors switched?   \n",
       "6                             New communities update!   \n",
       "7   I struggle to read cursive so I tested OCR han...   \n",
       "8   Old Results compared with the new ones + commu...   \n",
       "9   This is the plantation my 6th great-grandmothe...   \n",
       "10         Half sibling uncle, shared DNA percentage?   \n",
       "11                                   Updated results.   \n",
       "12  Illustrative DNA results (Spanish,German,Apach...   \n",
       "13  can someone shed some light onto my GF's resul...   \n",
       "14  my mom's mom got her DNA done and am just curi...   \n",
       "15  Hereâ€™s some of the tests Iâ€™ve taken. IMO MyHer...   \n",
       "16                     Mine  ; Son's Ancestry Results   \n",
       "17  Is it rare for a fully colonial WASP American ...   \n",
       "18                             is my Irish, Scottish?   \n",
       "19              adopted child interested in ethnicity   \n",
       "\n",
       "                                             selftext    subreddit  \\\n",
       "0                                                      AncestryDNA   \n",
       "1   send me a dm with your story pls! its for a ne...  AncestryDNA   \n",
       "2                                                      AncestryDNA   \n",
       "3                                                      AncestryDNA   \n",
       "4                                                      AncestryDNA   \n",
       "5                                                      AncestryDNA   \n",
       "6                                                      AncestryDNA   \n",
       "7                                           [removed]  AncestryDNA   \n",
       "8                                                      AncestryDNA   \n",
       "9   I feel surprisingly emotional about thisâ€¦ Weir...  AncestryDNA   \n",
       "10                                          [removed]  AncestryDNA   \n",
       "11                                                     AncestryDNA   \n",
       "12                                                     AncestryDNA   \n",
       "13                                                     AncestryDNA   \n",
       "14                                          [removed]  AncestryDNA   \n",
       "15                                                     AncestryDNA   \n",
       "16                                                     AncestryDNA   \n",
       "17  [removed]\\n\\n[View Poll](https://www.reddit.co...  AncestryDNA   \n",
       "18                                          [removed]  AncestryDNA   \n",
       "19                                          [removed]  AncestryDNA   \n",
       "\n",
       "                                       selftext_clean  \\\n",
       "0                                                  []   \n",
       "1                   [send, story, newspaper, article]   \n",
       "2                                                  []   \n",
       "3                                                  []   \n",
       "4                                                  []   \n",
       "5                                                  []   \n",
       "6                                                  []   \n",
       "7                                           [removed]   \n",
       "8                                                  []   \n",
       "9   [feel, surprisingly, emotional, thisâ€¦, weird, ...   \n",
       "10                                          [removed]   \n",
       "11                                                 []   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14                                          [removed]   \n",
       "15                                                 []   \n",
       "16                                                 []   \n",
       "17  [removed, view, poll, http, //www.reddit.com/p...   \n",
       "18                                          [removed]   \n",
       "19                                          [removed]   \n",
       "\n",
       "                                          title_clean  \n",
       "0   [using, wale, example, area, city, highlighted...  \n",
       "1   [anyone, ever, unusual, surprising, ancestry/2...  \n",
       "2                                 [result, community]  \n",
       "3   [percent, british, irish, 23andme, however, my...  \n",
       "4                      [result, know, parent, parent]  \n",
       "5                                   [color, switched]  \n",
       "6                                 [community, update]  \n",
       "7   [struggle, read, cursive, tested, handwriting,...  \n",
       "8        [result, compared, community, family, oh/nw]  \n",
       "9   [plantation, great-grandmother, mulatto, slave...  \n",
       "10         [half, sibling, uncle, shared, percentage]  \n",
       "11                                  [updated, result]  \n",
       "12  [illustrative, result, spanish, german, apache...  \n",
       "13  [someone, shed, light, onto, result, suspected...  \n",
       "14                              [done, curious, part]  \n",
       "15         [test, taken, myheritage, worst, estimate]  \n",
       "16                           [mine, ancestry, result]  \n",
       "17  [rare, fully, colonial, wasp, american, scotland]  \n",
       "18                                  [irish, scottish]  \n",
       "19            [adopted, child, interested, ethnicity]  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_posts_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c52e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments['body_length'] = lactose_df_comments['body_clean'].apply(lambda x : len(x))\n",
    "lactose_df_posts['selftext_length'] = lactose_df_posts['selftext_clean'].apply(lambda x : len(x))\n",
    "lactose_df_posts['title_length'] = lactose_df_posts['title_clean'].apply(lambda x : len(x))\n",
    "\n",
    "lactose_df_comments = lactose_df_comments[lactose_df_comments['body_length'] >= 5]\n",
    "lactose_df_posts = lactose_df_posts[lactose_df_posts['selftext_length'] >= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2ef87f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_comments_df['body_length'] = genome_comments_df['body_clean'].apply(lambda x : len(x))\n",
    "genome_posts_df['selftext_length'] = genome_posts_df['selftext_clean'].apply(lambda x : len(x))\n",
    "genome_posts_df['title_length'] = genome_posts_df['title_clean'].apply(lambda x : len(x))\n",
    "\n",
    "genome_comments_df= genome_comments_df[genome_comments_df['body_length'] >= 5]\n",
    "genome_posts_df= genome_posts_df[genome_posts_df['selftext_length'] >= 5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c286bc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments = lactose_df_comments.drop(columns=['body_length'])\n",
    "lactose_df_posts = lactose_df_posts.drop(columns=['title_length','selftext_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2b972c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_comments_df = genome_comments_df.drop(columns=['body_length'])\n",
    "genome_posts_df = genome_posts_df.drop(columns=['title_length','selftext_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "54ed60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = pd.concat([lactose_df_posts['title_clean'], lactose_df_posts['selftext_clean'], lactose_df_comments['body_clean']])\n",
    "bigram1 = Phrases(docs1, min_count=10)\n",
    "trigram1 = Phrases(bigram1[docs1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fe474e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs3 = pd.concat([genome_posts_df['title_clean'], genome_posts_df['selftext_clean'], genome_comments_df['body_clean']])\n",
    "bigram3 = Phrases(docs3, min_count=10)\n",
    "trigram3 = Phrases(bigram3[docs3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "12d3c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc is of type - list. Expecting the tokenized sentences \n",
    "def add_ngram(doc): \n",
    "    return trigram3[bigram3[doc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e35d0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_comments['body_ngrams'] = lactose_df_comments['body_clean'].apply(lambda x : add_ngram(x))\n",
    "lactose_df_posts['selftext_ngrams'] = lactose_df_posts['selftext_clean'].apply(lambda x : add_ngram(x))\n",
    "lactose_df_posts['title_ngrams'] = lactose_df_posts['title_clean'].apply(lambda x : add_ngram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7fb5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_comments_df['body_ngrams'] = genome_comments_df['body_clean'].apply(lambda x : add_ngram(x))\n",
    "genome_posts_df['selftext_ngrams'] = genome_posts_df['selftext_clean'].apply(lambda x : add_ngram(x))\n",
    "genome_posts_df['title_ngrams'] = genome_posts_df['title_clean'].apply(lambda x : add_ngram(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e46ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6992, 14)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a954363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41813, 11)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lactose_df_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3943f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25852, 13)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_posts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0769dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768767, 10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genome_comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0334a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lactose_df_posts.to_pickle('lactose_posts')\n",
    "lactose_df_comments.to_pickle('lactose_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a8e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_posts_df.to_pickle('genome_posts')\n",
    "genome_comments_df.to_pickle('genome_comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b17619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
